{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature_engine:\n",
    "    \n",
    "    pd = __import__('pandas')\n",
    "    datetime = __import__('datetime')\n",
    "    mcal = __import__('pandas_market_calendars')\n",
    "    np = __import__('numpy')\n",
    "    \n",
    "    def __init__(self):\n",
    "        print('feature_engine V.0.1 \\nImported pandas,datetime,pandas_market_calendars,numpy packages')\n",
    "        \n",
    "    def calc_price_change(self,tweet_time,financial_data,time_col_name,price_col_name,interval,amount,method='both',\n",
    "                          logdiff=True):\n",
    "        #remove seconds to match financial data format\n",
    "        tweet_time=tweet_time.replace(second=0)\n",
    "        #default baseline is set for five minutes before tweet\n",
    "        tweet_time_5min_before=tweet_time - self.datetime.timedelta(0,0,0,0,5)\n",
    "        \n",
    "        tweet_price=financial_data[financial_data[time_col_name]==tweet_time_5min_before][price_col_name]\n",
    "        if len(tweet_price)==0:\n",
    "            return float('NaN')\n",
    "        tweet_price.reset_index(inplace=True,drop=True)\n",
    "\n",
    "        def calculation(financial_data,time_col_name,new_time,price_col_name,tweet_price,direction,logdiff):\n",
    "            \n",
    "            other_price=financial_data[financial_data[time_col_name]==new_time][price_col_name]\n",
    "            other_price.reset_index(inplace=True,drop=True)\n",
    "            if len(other_price)==0:\n",
    "                return float('NaN')\n",
    "            elif logdiff:\n",
    "                if direction=='forward':\n",
    "                    return (self.np.log(other_price.iloc[0]) - self.np.log(tweet_price.iloc[0]))\n",
    "                elif direction=='backward':\n",
    "                    return (self.np.log(tweet_price.iloc[0]) - self.np.log(other_price.iloc[0]))\n",
    "            else:\n",
    "                if direction=='forward':\n",
    "                    return ((other_price.iloc[0]/tweet_price.iloc[0])-1)\n",
    "                elif direction=='backward':\n",
    "                    return ((tweet_price.iloc[0]/other_price.iloc[0])-1)\n",
    "\n",
    "        if (method=='both') or (method=='forward'):  \n",
    "            if interval=='minutes':\n",
    "                time_forward=tweet_time + self.datetime.timedelta(0,0,0,0,amount)\n",
    "            elif interval=='hours':\n",
    "                time_forward=tweet_time + self.datetime.timedelta(0,0,0,0,0,amount)\n",
    "            elif interval=='days':\n",
    "                time_forward=tweet_time + self.datetime.timedelta(amount,0,0,0,0)\n",
    "            pct_change_forward=calculation(financial_data,time_col_name,time_forward,price_col_name,tweet_price,'forward',\n",
    "                                          logdiff)\n",
    "\n",
    "        if (method=='both') or (method=='backward'): \n",
    "            if interval=='minutes':\n",
    "                time_backward=tweet_time - self.datetime.timedelta(0,0,0,0,amount)   \n",
    "            elif interval=='hours':\n",
    "                time_backward=tweet_time - self.datetime.timedelta(0,0,0,0,0,amount) \n",
    "            elif interval=='days':\n",
    "                time_backward=tweet_time - self.datetime.timedelta(amount,0,0,0,0)\n",
    "            pct_change_backward=calculation(financial_data,time_col_name,time_backward,price_col_name,tweet_price,'backward'\n",
    "                                           ,logdiff)\n",
    "        \n",
    "        if method == 'both':\n",
    "            return self.pd.DataFrame({f'{amount}_{interval}_forward_pct_change':pct_change_forward,\n",
    "                          f'{amount}_{interval}_backward_pct_change':pct_change_backward},index=[0])\n",
    "        elif method=='backward':\n",
    "            return self.pd.DataFrame({f'{amount}_{interval}_backward_pct_change':pct_change_backward},index=[0])\n",
    "        elif method=='forward':\n",
    "            return self.pd.DataFrame({f'{amount}_{interval}_forward_pct_change':pct_change_forward},index=[0])\n",
    "        \n",
    "    def create_pricechg_columns(self,twitter_data,tweet_time_col_name,financial_data,fin_time_col_name,price_col_name,\n",
    "                       interval_amount_dict,method='both',logdiff=True):\n",
    "        from tqdm import tqdm\n",
    "        new_columns=self.pd.DataFrame()\n",
    "        for i, row in tqdm(twitter_data.iterrows()):\n",
    "            temp_df=self.pd.DataFrame()\n",
    "            for interval, amount in interval_amount_dict:\n",
    "                new_df=self.calc_price_change(twitter_data[tweet_time_col_name].loc[i],financial_data,fin_time_col_name,\n",
    "                                                   price_col_name,interval,amount,method,logdiff)\n",
    "                if not isinstance(new_df,float):\n",
    "                    temp_df=self.pd.concat([temp_df,new_df],axis=1)\n",
    "            for item in temp_df.columns:\n",
    "                new_columns.at[i,item] = temp_df.loc[0,item]\n",
    "        return new_columns\n",
    "    \n",
    "    def mean_encoding_tocolumn(self,features_df,categorical_column,target_column):\n",
    "        features_df=features_df[[categorical_column,target_column]]\n",
    "        grouped=features_df.groupby([categorical_column]).mean()\n",
    "        features_df=features_df.merge(grouped,on=categorical_column)\n",
    "        return features_df[f'{target_column}_y']\n",
    "    \n",
    "    def mean_encoding_todict(self,features_df,categorical_column,target_column):\n",
    "        features_df=features_df[[categorical_column,target_column]]\n",
    "        return features_df.groupby([categorical_column]).mean()\n",
    "    \n",
    "    def calculate_sum_volume(self,tweet_time,financial_data,time_col_name,volume_col_name,interval,amount):\n",
    "        #remove seconds to match financial data format\n",
    "        tweet_time=tweet_time.replace(second=0)\n",
    "#         default baseline is set for five minutes before tweet\n",
    "        tweet_time_5min_before=tweet_time - self.datetime.timedelta(0,0,0,0,5)\n",
    "        \n",
    "        def calculation(financial_data,time_col_name,time_forward,time_backward,volume_col_name,tweet_time):\n",
    "            forward_volume_sum=sum(financial_data.loc[(financial_data[time_col_name]<=time_forward) & \n",
    "                                        (financial_data[time_col_name]>=tweet_time)][volume_col_name])\n",
    "            backward_volume_sum=sum(financial_data.loc[(financial_data[time_col_name]<=tweet_time) & \n",
    "                                        (financial_data[time_col_name]>=time_backward)][volume_col_name])\n",
    "            if backward_volume_sum != 0:\n",
    "                return forward_volume_sum/backward_volume_sum\n",
    "            else:\n",
    "                return self.np.nan\n",
    "\n",
    "        if interval=='minutes':\n",
    "            time_forward=tweet_time + self.datetime.timedelta(0,0,0,0,amount)\n",
    "            time_backward=tweet_time - self.datetime.timedelta(0,0,0,0,amount)\n",
    "        elif interval=='hours':\n",
    "            time_forward=tweet_time + self.datetime.timedelta(0,0,0,0,0,amount)\n",
    "            time_backward=tweet_time - self.datetime.timedelta(0,0,0,0,0,amount)\n",
    "        elif interval=='days':\n",
    "            time_forward=tweet_time + self.datetime.timedelta(amount,0,0,0,0)\n",
    "            time_backward=tweet_time - self.datetime.timedelta(amount,0,0,0,0)\n",
    "        vol_sum=calculation(financial_data,time_col_name,time_forward, time_backward, volume_col_name,tweet_time_5min_before)\n",
    "\n",
    "        return self.pd.DataFrame({f'{amount}_{interval}_forward_vol_sum':vol_sum},index=[0])\n",
    "        \n",
    "    def create_volumesum_columns(self,twitter_data,tweet_time_col_name,financial_data,fin_time_col_name,volume_col_name,\n",
    "                       interval_amount_dict):\n",
    "        from tqdm import tqdm\n",
    "        new_columns=self.pd.DataFrame()\n",
    "        for i, row in tqdm(twitter_data.iterrows()):\n",
    "            temp_df=self.pd.DataFrame()\n",
    "            for interval, amount in interval_amount_dict:\n",
    "                new_df=self.calculate_sum_volume(twitter_data[tweet_time_col_name].loc[i],financial_data,fin_time_col_name,\n",
    "                                                   volume_col_name,interval,amount)\n",
    "                if not isinstance(new_df,float):\n",
    "                    temp_df=self.pd.concat([temp_df,new_df],axis=1)\n",
    "            for item in temp_df.columns:\n",
    "                new_columns.at[i,item] = temp_df.loc[0,item]\n",
    "        return new_columns\n",
    "    \n",
    "    def fill_missing_fin_data(self,ticker_col_name,stock_exchg_name,start_date,end_date,frequency,fin_time_colname,\n",
    "                          financial_data,volume_colname,price_colname):\n",
    "        ticker_name=financial_data.iloc[0][ticker_col_name]\n",
    "        stock_exchg = self.mcal.get_calendar(stock_exchg_name, open_time=self.datetime.time(5, 30), \n",
    "                                             close_time=self.datetime.time(12, 0))\n",
    "        daterange = stock_exchg.schedule(start_date, end_date)\n",
    "        dates=self.pd.DataFrame(self.mcal.date_range(daterange, frequency).tz_convert(None),columns=[fin_time_colname])\n",
    "\n",
    "#         financial_data[fin_time_colname] = self.pd.to_datetime(financial_data[fin_time_colname], utc = True)\n",
    "\n",
    "        financial_data=dates.merge(financial_data,on=fin_time_colname,how='left')\n",
    "        financial_data[ticker_col_name]=ticker_name\n",
    "\n",
    "        financial_data['SYM_SUFFIX'].fillna(0,inplace=True)\n",
    "\n",
    "        financial_data[volume_colname].fillna(0,inplace=True)\n",
    "        financial_data[price_colname].interpolate(inplace=True)\n",
    "        return financial_data\n",
    "    \n",
    "    def token_matrix(self,text_column,financial_topic_words):\n",
    "        \n",
    "        def check_for_word(token_vector,word):\n",
    "            if word in token_vector:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "            \n",
    "        new_df=self.pd.DataFrame()\n",
    "        for topic_word in financial_topic_words:\n",
    "            new_df[topic_word]=text_column.apply(lambda x:check_for_word(x.lower().split(),topic_word))\n",
    "            \n",
    "        return new_df\n",
    "    \n",
    "    def diff_from_meanlog(self,df,date_colname,numeric_colname):\n",
    "        #This function returns the difference of logs between the original value and that month's average\n",
    "        ins_df=df[[date_colname,numeric_colname]].copy().set_index(date_colname,drop=True).astype(int).resample(\"M\").mean()\n",
    "        ins_df[numeric_colname]=self.np.log(ins_df[numeric_colname].replace(0, np.nan))\n",
    "        ins_df['month']=ins_df.index.map(str).str[:7]\n",
    "        df['month']=df[date_colname].map(str).str[:7]\n",
    "        averages=df[[date_colname,'month']].merge(ins_df,on='month',how='left')[numeric_colname]\n",
    "        diff=self.np.log(df[numeric_colname].replace(0, np.nan))-averages\n",
    "        return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_data=pd.read_csv('04052009-10062020-SPYDIA-minutedata.csv',parse_dates=['DATETIME'])\n",
    "twitter_data=pd.read_csv('trump_tweets_reducted_after_nlp.csv',index_col=0,parse_dates=['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_data=financial_data[financial_data['SYM_ROOT']=='SPY']\n",
    "dow_data=financial_data[financial_data['SYM_ROOT']=='DIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_engine V.0.1 \n",
      "Imported pandas,datetime,pandas_market_calendars,numpy packages\n"
     ]
    }
   ],
   "source": [
    "feat_eng = feature_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data['retweet_count']=feat_eng.diff_from_meanlog(twitter_data,'created_at','retweet_count')\n",
    "twitter_data['favorite_count']=feat_eng.diff_from_meanlog(twitter_data,'created_at','favorite_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>SYM_ROOT</th>\n",
       "      <th>SYM_SUFFIX</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-05-04 04:15:00</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5300</td>\n",
       "      <td>88.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-05-04 04:26:00</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>88.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-05-04 04:35:00</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2800</td>\n",
       "      <td>88.555000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-05-04 04:42:00</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600</td>\n",
       "      <td>88.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-05-04 04:50:00</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>88.542000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480594</th>\n",
       "      <td>2020-06-10 19:56:00</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15755</td>\n",
       "      <td>316.709474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480596</th>\n",
       "      <td>2020-06-10 19:57:00</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9300</td>\n",
       "      <td>316.691556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480598</th>\n",
       "      <td>2020-06-10 19:58:00</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7978</td>\n",
       "      <td>316.655902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480600</th>\n",
       "      <td>2020-06-10 19:59:00</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54390</td>\n",
       "      <td>316.646667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480602</th>\n",
       "      <td>2020-06-10 20:00:00</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>538727</td>\n",
       "      <td>319.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2165945 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   DATETIME SYM_ROOT  SYM_SUFFIX    SIZE       PRICE\n",
       "0       2009-05-04 04:15:00      SPY         0.0    5300   88.637500\n",
       "1       2009-05-04 04:26:00      SPY         0.0     100   88.660000\n",
       "2       2009-05-04 04:35:00      SPY         0.0    2800   88.555000\n",
       "3       2009-05-04 04:42:00      SPY         0.0     600   88.600000\n",
       "4       2009-05-04 04:50:00      SPY         0.0     500   88.542000\n",
       "...                     ...      ...         ...     ...         ...\n",
       "3480594 2020-06-10 19:56:00      SPY         0.0   15755  316.709474\n",
       "3480596 2020-06-10 19:57:00      SPY         0.0    9300  316.691556\n",
       "3480598 2020-06-10 19:58:00      SPY         0.0    7978  316.655902\n",
       "3480600 2020-06-10 19:59:00      SPY         0.0   54390  316.646667\n",
       "3480602 2020-06-10 20:00:00      SPY         0.0  538727  319.000000\n",
       "\n",
       "[2165945 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_data=feat_eng.fill_missing_fin_data('SYM_ROOT','NYSE','2009-05-04','2020-06-10','1min','DATETIME',\n",
    "                          sp500_data,'SIZE','PRICE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow_data=feat_eng.fill_missing_fin_data('SYM_ROOT','NYSE','2009-05-04','2020-06-10','1min','DATETIME',\n",
    "                          dow_data,'SIZE','PRICE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sum of volume will be log difference from mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:15,  1.40it/s]"
     ]
    }
   ],
   "source": [
    "tweets_finance_volume=feat_eng.create_volumesum_columns(twitter_data[['created_at']],'created_at',\n",
    "                                                        dow_data[['DATETIME','SIZE']],'DATETIME','SIZE',\n",
    "                       [('minutes',1),('minutes',5),('minutes',10),('minutes',15),('minutes',30),('hours',1),\n",
    "                        ('hours',3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_finance_volume=tweets_finance_volume.join(twitter_data[['created_at_utc']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 36732 entries, 0 to 36731\n",
      "Data columns (total 9 columns):\n",
      "1_minutes_forward_vol_sum     9646 non-null float64\n",
      "5_minutes_forward_vol_sum     9720 non-null float64\n",
      "10_minutes_forward_vol_sum    9789 non-null float64\n",
      "15_minutes_forward_vol_sum    9832 non-null float64\n",
      "30_minutes_forward_vol_sum    9909 non-null float64\n",
      "1_hours_forward_vol_sum       10044 non-null float64\n",
      "3_hours_forward_vol_sum       36732 non-null float64\n",
      "created_at_utc                36732 non-null datetime64[ns]\n",
      "month                         36732 non-null object\n",
      "dtypes: datetime64[ns](1), float64(7), object(1)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets_finance_volume=tweets_finance_volume.replace([np.inf, -np.inf], float('nan'))\n",
    "tweets_finance_volume.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36732it [11:05:01,  7.88it/s]  \n"
     ]
    }
   ],
   "source": [
    "tweets_finance=feat_eng.create_pricechg_columns(twitter_data[['created_at_utc']],'created_at_utc',dow_data,\n",
    "                                                'DATETIME','PRICE',[('minutes',1),('minutes',5),('minutes',10),\n",
    "                                                                    ('minutes',15),('minutes',30),('hours',1),\n",
    "                                                                    ('hours',3),('hours',6)],\n",
    "                                                                    method='forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data_with_finance=twitter_data.join(tweets_finance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data_with_finance=twitter_data_with_finance.join(tweets_finance_volume.drop(['created_at_utc','month'],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data_with_finance.drop(['coordinates','extended_entities','geo','in_reply_to_screen_name',\n",
    "                                             'in_reply_to_status_id','in_reply_to_user_id','is_quote_status','is_retweet',\n",
    "                                             'lang','place','possibly_sensitive','quoted_status','quoted_status_id','id',\n",
    "                                             'retweeted_status','retrieved_utc'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data_with_finance=twitter_data_with_finance.join(pd.get_dummies(twitter_data_with_finance['source']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data=pd.DataFrame()\n",
    "financial_data=pd.DataFrame()\n",
    "dow_data=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data_with_finance=twitter_data_with_finance.drop(['source','truncated'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words=['china','chinese','nafta','trade','trades','trading','tariff','tariffs','opec','usmca','xi','jinping','sanctions',\n",
    "            'market','markets','stock','stocks','financial','investment','dow','nasdaq','500','wall street','wall st',\n",
    "            'unemployment','jobs','labor',\n",
    "            'manufacture','manufacturers','consumer','consumers','bank','banks','factories','business','businesses'\n",
    "               ,'corporate','corporates','industry','industries','product','agriculture','agricultural','products',\n",
    "            'rate','rates','reserve','inflation','currency','depreciating','depreceate','fed','federal reserve',\n",
    "            'deal','deals',\n",
    "             'dollar','dollars','$',\n",
    "             'billion','billions','gdp','growth',\n",
    "             'revenue','economy','economies','economist','economic','economists','money',\n",
    "             'companies',\n",
    "             'price','prices',\n",
    "             'cents','cent','purchase',\n",
    "             'depletion','regulation',\n",
    "             '401(k)','trillions','recession','depression',\n",
    "            'taxes','taxation','tax','debt','deficit','spending','refinance','finance','savings','deficits','bankruptcy',\n",
    "              'spend','cost','costs','subsidizing','subsidize',\n",
    "            'iran','nuclear','wall','military','daca','bill','danger','conflict','rockets','russia',\n",
    "                 'middle east','ukrainian','ukraine','isis','syria','border','russian','investigation','kim','jong','un',\n",
    "                'caravan','sanctions','corona','virus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_words_matrix=feat_eng.token_matrix(twitter_data_with_finance['text'],topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data_with_finance=twitter_data_with_finance.join(financial_words_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_data_with_finance['trump_president']=twitter_data_with_finance['created_at_utc']>='2016-11-08 22:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_data_with_finance.drop('text',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_data_with_finance=twitter_data_with_finance.join(pd.get_dummies(twitter_data_with_finance['lda_topic']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_data_with_finance_for_analysis.drop('lda_topic',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data_with_finance.to_csv('twitter_data_with_dow_for_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in twitter_data_with_finance_for_analysis[twitter_data_with_finance_for_analysis['currency']==1]['text']:\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
